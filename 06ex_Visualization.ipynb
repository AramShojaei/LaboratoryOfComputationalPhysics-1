{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Kernel Density Estimate**\n",
    "\n",
    "Produce a KDE for a given distribution (by hand, not using seaborn!):\n",
    "\n",
    "* Fill a numpy array, x,  of len(N) (with N=O(100)) with a variable normally distributed, with a given mean a standard deviation\n",
    "* Fill an histogram in pyplot taking properly care about the aesthetic\n",
    "   * use a meaningful number of bins\n",
    "   * set a proper y axis label\n",
    "   * set proper value of y axis major ticks labels (e.g. you want to display only integer labels)\n",
    "   * display the histograms as data points with errors (the error being the poisson uncertainty)\n",
    "* for every element of x, create a gaussian with the mean corresponding the element value and std as a parameter that can be tuned. The std default value should be:\n",
    "$$ 1.06 * x.std() * x.size ^{-\\frac{1}{5.}} $$\n",
    "you can use the scipy function `stats.norm()` for that.\n",
    "* In a separate plot (to be placed beside the original histogram), plot all the gaussian functions so obtained\n",
    "* Sum (with np.sum()) all the gaussian functions and normalize the result such that the integral matches the integral of the original histogram. For that you could use the `scipy.integrate.trapz()` method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # N-dimensional array / broadcasting / random numbers\n",
    "import matplotlib.pyplot as plt # graphs\n",
    "#from matplotlib.ticker import AutoMinorLocator, MultipleLocator, FuncFormatter\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import pandas as pd # DataFrame and label-based slicing\n",
    "import seaborn as sns  # data visualization\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-33c137d065fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstd_gauss\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;36m1.06\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd_gauss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstd_gauss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "np.linspace(0,y.max(),10,dtype=int)\n",
    "std_gauss  = 1.06*x.std()*(x.size**(-1/5))\n",
    "print(std_gauss)\n",
    "sp.stats.norm.pdf(x,loc=x[1],scale=std_gauss).shape\n",
    "len(b_height)\n",
    "len(b_edges)\n",
    "print(y.shape)\n",
    "print(norm_gauss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the number of bins and the bins sizes needs a lot of care. Typically the content of each $i$th bin, $N_i$, should be statistically significant, i.e. the corresponding Poisson uncertainty, $1/\\sqrt{N_i}$, should be small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std,N=0,1,100\n",
    "x=np.random.normal(mean,std,N)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14,7))\n",
    "n_bins=10\n",
    "b_height, b_edges, _  = ax1.hist(x,bins=n_bins,histtype='step',label='My distribution',color='blue')\n",
    "\n",
    "central_points = (b_edges[1:]+b_edges[:-1])/2\n",
    "ax1.errorbar(central_points, b_height, 1/np.sqrt(b_height), fmt = 'none', label = \"Errorbars\", ecolor=\"red\")\n",
    "\n",
    "ax1.set_title('Histogram and KDE')\n",
    "ax1.set_ylabel('Frequencies')\n",
    "ax1.set_yticks(ticks=np.linspace(0,y.max(),10,dtype=int))\n",
    "\n",
    "std_gauss  = 1.06*x.std()*(x.size**(-1/5))\n",
    "\n",
    "ax2.set_title('gaussian')\n",
    "ax2.set_ylabel('gaussian distributions')\n",
    "n=1000\n",
    "somma=np.zeros((x.size,x.size))\n",
    "m=0\n",
    "for i in x:  \n",
    "    interval=np.linspace(i-3*std_gauss,i+3*std_gauss, N)\n",
    "    ax2.plot(interval, sp.stats.norm.pdf(interval,loc=i,scale=std_gauss),ls='-')\n",
    "    somma[m,:]=sp.stats.norm.pdf(x,loc=i,scale=std_gauss)\n",
    "    #print(sp.stats.norm.pdf(x,loc=i,scale=std_gauss))\n",
    "    m +=1\n",
    "    \n",
    "\n",
    "y=np.sum(somma,axis=0)\n",
    "norm_gauss = sp.integrate.trapz(b_height,b_edges[1:])\n",
    "ax1.plot(x,y/N*norm_gauss,'go',label='KDE')\n",
    "ax1.legend(markerscale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **Color-coded scatter plot**\n",
    "\n",
    "Produce a scatter plot out of a dataset with two categories\n",
    "\n",
    "* Write a function that generate a 2D datasets of 2 categories. Each category should distribute as a 2D gaussian with a given mean and std (clearly it is better to have different values means..)\n",
    "* Display the dataset in a scatter plot marking the two categories with different marker colors.\n",
    "\n",
    "An example is given below\n",
    "\n",
    "You can try to make the procedure more general by allowing a given number $n\\ge 2$ of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# always useful\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ! wget https://www.dropbox.com/s/u4y3k4kk5tc7j46/two_categories_scatter_plot.png\n",
    "from IPython.display import Image\n",
    "Image('../data/two_categories_scatter_plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat=10 \n",
    "mean=20 \n",
    "std=2 \n",
    "lowest=100 \n",
    "highest=1000 \n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 10))\n",
    "lowest=100 \n",
    "highest=1000 \n",
    "for i in range(n_cat):\n",
    "    size=np.random.randint(lowest,highest)\n",
    "    m1=np.random.uniform(-mean,mean)\n",
    "    m2=np.random.uniform(-mean,mean)\n",
    "    std1=np.random.uniform(0,std)\n",
    "    std2=np.random.uniform(0,std)\n",
    "\n",
    "    x = np.random.normal(m1,std1,size)\n",
    "    y = np.random.normal(m2,std2,size)\n",
    "\n",
    "    ax.scatter(x,y,alpha=0.7,marker='*',label='cat_set'+str(i+1))\n",
    "\n",
    "ax.grid(True)\n",
    "ax.legend(markerscale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **Profile plot**\n",
    "\n",
    "Produce a profile plot from a scatter plot.\n",
    "* Download the following dataset and load it as a pandas dataframe:\n",
    "```bash\n",
    "wget https://www.dropbox.com/s/hgnvyj9abatk8g6/residuals_261.npy\n",
    "```\n",
    "Note that you should you the `np.load()` function to load the file as a numpy array and then pass it to the `pd.DataFrame()` constructor.\n",
    "* Inspect the dataset, you'll find two variables (features)\n",
    "* Clean the sample by selecting the entries (rows) with the variable \"residual\" in absolute value smaller than 2\n",
    "* perform a linear regression of \"residuals\" versus \"distances\" using `scipy.stats.linregress()` \n",
    "* plot a seaborn jointplot of  \"residuals\" versus \"distances\", having seaborn performing a linear regression. The result of the regression should be displayed on the plot\n",
    "* Fill 3 numpy arrays\n",
    "  * x, serving as an array of bin centers for the \"distance\" variable. It should range from 0 to 20 with reasonable number of steps (bins)\n",
    "  * y, the mean values of the \"residuals\", estimated in slices (bins) of \"distance\"\n",
    "  * erry, the standard deviation of the  of the \"residuals\", estimated in slices (bins) of \"distance\"\n",
    "* Plot the profile plot on top of the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.load('../data/residuals_261.npy').item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of paramount importance is the condensation of the scatter plots into \"profiles\". The procedure runs as follow: data are binned along the $x$ (if you had to bin on the other variable, just invert the axes), for every bin take the mean and the standard deviation of the corresponding $y$ values, display those as data points and their error.\n",
    "These are also called \"box plots\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOINTPLOT with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df[np.absolute(df['residuals'])<2]\n",
    "#x are distances, y are residuals\n",
    "slope,intercept,_, _, _ = sp.stats.linregress(df_cleaned['distances'],df_cleaned['residuals'])\n",
    "#{0:.3f} 0 is the argument, .3f is the number's format\n",
    "joint = sns.jointplot(x = \"distances\", y = \"residuals\", data = df_cleaned, kind=\"reg\",scatter_kws={'alpha':0.2},joint_kws={'label':\"y={0:.3f}x+{1:.3f}\".format(slope,intercept)},color='blue')\n",
    "joint.ax_joint.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROFILE PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{0:.3f} 0 is the argument, .3f is the number's format\n",
    "joint = sns.jointplot(x = \"distances\", y = \"residuals\", data = df_cleaned, kind=\"reg\",scatter_kws={'alpha':0.2},joint_kws={'label':\"y={0:.3f}x+{1:.3f}\".format(slope,intercept)},color='blue')\n",
    "joint.ax_joint.legend()\n",
    "\n",
    "#getting the bin centers\n",
    "nbin=20 \n",
    "bin_edges = np.linspace(0,20,nbin+1)\n",
    "central_points =(bin_edges[1:] + bin_edges[:-1])/2 \n",
    "\n",
    "#filling the array\n",
    "#y=mean, red point of the profile plot\n",
    "#erry=error bar size\n",
    "y=np.array([df_cleaned.loc[(df_cleaned['distances'] >=bin_edges[i]) & (df_cleaned['distances'] <bin_edges[i+1])]['residuals'].mean() for i in range(nbin)])\n",
    "erry=np.array([df_cleaned.loc[(df_cleaned['distances'] >=bin_edges[i]) & (df_cleaned['distances'] <bin_edges[i+1])]['residuals'].std() for i in range(nbin)])\n",
    "#plotting profile\n",
    "plt.errorbar(central_points,y,yerr=erry, label='Profile Plot',linewidth=1.5,color='r',marker='o')\n",
    "joint.ax_joint.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
